{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import backbones_unet\n",
    "import cv2\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.load(\"../ckpts/convnext_base_ckpt5.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n",
      "9\n",
      "torch.Size([9, 3, 224, 224])\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]]], device='cuda:0')\n",
      "[0.7825327515602112, 0.5509573221206665, 0.680998682975769, 0.8986495137214661, 0.5911381244659424, 0.7307940721511841, 0.7439268231391907, 0.5549081563949585]\n",
      "torch.Size([180, 1, 224, 224])\n",
      "165\n"
     ]
    }
   ],
   "source": [
    "def jaccard_index(predicted, target):\n",
    "    intersection = (predicted * target).sum()\n",
    "    union = (predicted + target).sum() - intersection\n",
    "    return (intersection / (union + 1e-6)).item()\n",
    "\n",
    "def preprocess(img):\n",
    "    img = img.resize((224, 224)) \n",
    "    img = torch.Tensor(np.array(img, dtype=np.uint8).transpose((2, 0, 1)))\n",
    "    img = img.float() / 255.0\n",
    "    return img\n",
    "\n",
    "def get_video_frame(in_path):\n",
    "    cap = cv2.VideoCapture(in_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    print(fps)\n",
    "    frames = []\n",
    "    start_time = time()\n",
    "    try:\n",
    "        while True:\n",
    "            # Read a frame from the video\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break  # Break the loop if there are no frames left\n",
    "            \n",
    "            # Optionally resize or preprocess the frame here if necessary\n",
    "            frames.append(frame)\n",
    "    finally:\n",
    "        cap.release()  # Make sure to release the video capture object\n",
    "    \n",
    "    return frames, fps\n",
    "\n",
    "frames, fps = get_video_frame(\"./videos/fast.mp4\")\n",
    "\n",
    "segment_every_x = 20\n",
    "\n",
    "def batched_segmentation(model,frames,segment_every_x):\n",
    "    chosen = frames[::segment_every_x]\n",
    "    print(len(chosen))\n",
    "    loss = []\n",
    "    chosen_converted = [cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) for frame in chosen]\n",
    "    chosen_preprocessed = [preprocess(Image.fromarray(rgb_frame)) for rgb_frame in chosen_converted]\n",
    "    batch = torch.stack(chosen_preprocessed,dim=0)\n",
    "    print(batch.shape)\n",
    "    #input to model\n",
    "    batch = batch.to('cuda')\n",
    "    model = model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        output = model(batch)\n",
    "    output = output.clamp(0,1)\n",
    "    print(output.clamp(0,1))\n",
    "    for i in range(output.shape[0]-1):\n",
    "        loss.append(jaccard_index(output[i][0],output[i+1][0]))\n",
    "    print(loss)\n",
    "    return output\n",
    "\n",
    "output = batched_segmentation(model,frames,segment_every_x)\n",
    "tensor_shape = output[0].shape\n",
    "extended_masks = output.unsqueeze(1).repeat(1, segment_every_x, 1, 1, 1).view(-1, *tensor_shape)\n",
    "print(extended_masks.shape)\n",
    "\n",
    "print(len(frames))\n",
    "chosen_converted_frames = [cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) for frame in frames]\n",
    "chosen_preprocessed_frames = [preprocess(Image.fromarray(rgb_frame)) for rgb_frame in chosen_converted_frames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 224, 224])\n",
      "torch.Size([180, 1, 224, 224])\n",
      "8\n",
      "reached!\n",
      "torch.Size([9, 1, 224, 224])\n",
      "Loss:0.7825303077697754\n",
      "Adding new interpolations,interval = 10\n",
      "torch.Size([9, 1, 224, 224])\n",
      "Loss:0.8113927245140076\n",
      "torch.Size([9, 1, 224, 224])\n",
      "Loss:0.5983411073684692\n",
      "Adding new interpolations,interval = 5\n",
      "torch.Size([9, 1, 224, 224])\n",
      "Loss:0.7189475297927856\n",
      "Adding new interpolations,interval = 2\n",
      "torch.Size([9, 1, 224, 224])\n",
      "Loss:0.8793796300888062\n",
      "torch.Size([9, 1, 224, 224])\n",
      "Loss:0.9252275228500366\n",
      "Combining subintervals, interval = 4\n",
      "torch.Size([9, 1, 224, 224])\n",
      "Loss:0.7772756814956665\n",
      "Adding new interpolations,interval = 2\n",
      "torch.Size([9, 1, 224, 224])\n",
      "Loss:0.9273473620414734\n",
      "Combining subintervals, interval = 4\n",
      "180\n"
     ]
    }
   ],
   "source": [
    "def single_pass(model,input):\n",
    "    input = cv2.cvtColor(input, cv2.COLOR_BGR2RGB)\n",
    "    input_preprocessed = preprocess(Image.fromarray(input))\n",
    "    input_preprocessed = input_preprocessed[None,...]\n",
    "    input_preprocessed = input_preprocessed.to('cuda')\n",
    "    model = model.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        output = model(input_preprocessed)\n",
    "    output = output.clamp(0,1)\n",
    "    return output[0]\n",
    "\n",
    "print(single_pass(model,frames[0]).shape)\n",
    "\n",
    "def frame_scheduling(frames,masks,output,segment_every_x,mode='linear'):\n",
    "    loss = []\n",
    "    cutoff = 0.8\n",
    "    upper_cutoff = 0.90\n",
    "    for i in range(output.shape[0]-1):\n",
    "        loss.append(jaccard_index(output[i][0],output[i+1][0]))\n",
    "    print(masks.shape)\n",
    "    print(len(loss))\n",
    "    if mode == 'linear':\n",
    "        for i in range(len(loss)): \n",
    "            if(loss[i] < cutoff):\n",
    "                print(\"Linear Interpolating...\")\n",
    "                for j in range(segment_every_x):\n",
    "                    alpha = j / (segment_every_x - 1)\n",
    "                    print(alpha)\n",
    "                    masks[i*segment_every_x + j] = torch.lerp(masks[i*segment_every_x],masks[i*segment_every_x + segment_every_x],alpha)\n",
    "                    \n",
    "    elif mode == 'trust region':\n",
    "        print(\"reached!\")\n",
    "        interval = segment_every_x\n",
    "        for i in range(len(loss)):\n",
    "            print(output.shape)\n",
    "            diff = jaccard_index(masks[i*segment_every_x][0],masks[i*segment_every_x+interval][0])\n",
    "            print(f\"Loss:{diff}\")\n",
    "            if(diff < cutoff) and interval > 2:\n",
    "                interval = interval // 2\n",
    "                print(f\"Adding new interpolations,interval = {interval}\")\n",
    "            elif interval*2 < segment_every_x and diff > upper_cutoff : \n",
    "                interval = interval * 2\n",
    "                print(f\"Combining subintervals, interval = {interval}\")\n",
    "            for subinterval in range(0,segment_every_x,interval):\n",
    "                index = i * segment_every_x + subinterval\n",
    "                new_mask = single_pass(model,frames[index])\n",
    "                masks[i*segment_every_x - interval + subinterval: i*segment_every_x + subinterval] = new_mask\n",
    "\n",
    "    return masks\n",
    "\n",
    "masks = frame_scheduling(frames,extended_masks,output,segment_every_x,mode='trust region')\n",
    "\n",
    "print(len(masks))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n",
      "180\n"
     ]
    }
   ],
   "source": [
    "def getVideo(frames,out_path,masks):\n",
    "    \n",
    "    H, W, C = frames[0].shape\n",
    "    segmented_frames = []\n",
    "    cnt = 0\n",
    "    #print(len(frames))\n",
    "    val_every_x_frame = 5\n",
    "    segmented_frames = []\n",
    "    print(len(frames))\n",
    "    print(len(masks))\n",
    "    for i in range(len(frames)):\n",
    "        segmented_frames.append(frames[i].to('cuda') * masks[i])\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')  # or (*'XVID') depending on the desired output format\n",
    "    out = cv2.VideoWriter(out_path, fourcc, 30.0, (224,224))\n",
    "    assert(len(segmented_frames) == len(frames))\n",
    "    for frame in segmented_frames:\n",
    "        frame = frame.permute(1, 2, 0)\n",
    "        frame = frame.cpu().numpy()\n",
    "        if frame.dtype != np.uint8:\n",
    "            frame = (frame * 255).astype(np.uint8)\n",
    "        #plt.imshow(frame)\n",
    "        #plt.show()\n",
    "        #print(frame.shape)\n",
    "        # Convert your processed frame back to BGR from RGB if necessary\n",
    "        bgr_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        out.write(bgr_frame)\n",
    "    out.release()  # Release everything if job is finished\n",
    "    end_time = time()\n",
    "    \n",
    "getVideo(chosen_preprocessed_frames,\"./videos/fast_out_trust_region.mp4\",extended_masks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
